print('annual inc')
median(xQuan$annual_inc)
print('revolving bal')
median(xQuan$revol_bal)
#Counting the missing data
sapply(xQuan, function(x) sum(is.na(x)))
#mode impute
modeImpute = function(Xqual){
tbl = table(Xqual)
Xqual[is.na(Xqual)] = names(tbl)[which.max(tbl)]
return(Xqual)
}
xQual = xQual %>% mutate(across(.cols=everything(), modeImpute))
#median impute
xQuan = xQuan %>%
preProcess(method = 'medianImpute')%>%
predict(newdata = xQuan)
#Counting the missing data again
sapply(xQual, function(x) sum(is.na(x)))
sapply(xQuan, function(x) sum(is.na(x)))
datacorr = cor(xQuan)
corrplot(datacorr, order= 'hclust', t1.cex= .35)
str(xQuan)
dim(xQuan)
#correlated features
highCorr = findCorrelation(datacorr, .85, verbose=T, names=T)
highCorr
#Removing correlated features
xQuan= select(all_of(xQuan), -any_of((highCorr)))
#Centering and scaling the numeric features (dont want to center and scale dummy variables)
xQuan = xQuan %>% preProcess(.) %>% predict(newdata = xQuan)
#Checking features for imbalanced frequencies. Pg 45 in the book recommends removing features if the fraction of unique values to sample size is low (10%) and the ratio of the most prevalent value to 2nd most prevalent value is large (around 20). if both criteria holds they say it may be advantageous to remove it. On pg 55 they show the code for this.
#I asked about this is the Q&A and he pretty much said either method is fine to use. I am going to try it without it.
#str(xQuan)
#freq = nearZeroVar(xQuan, saveMetrics = TRUE)
#xQuan = select_if(xQuan, freq$freqRatio < 30 | freq$percentUnique > 0.10)
#str(xQuan)
xFull = cbind(xQual, xQuan) # combine qualitative and quantitative features
dim(xFull)# total number of observations and features in the training set
names(xFull)# names of remaining features
table(xQual$last_credit_pull_d)
set.seed(1234567)
xFull = cbind(y, xFull) %>% as.data.frame()
n=nrow(xFull)
trainingDataIndex = createDataPartition(xFull$loan_status, p = .75, list = FALSE) %>% as.vector(.)
trainingData = xFull[trainingDataIndex, ]
testingData = xFull[-trainingDataIndex, ]
Xtrain = select(trainingData, -loan_status)
Xtest = select(testingData, -loan_status)
Ytrain = select(trainingData, loan_status) %>% unlist() %>% as.factor()
Ytest = select(testingData, loan_status) %>% unlist() %>% as.factor()
rm(trainingData)
rm(testingData)
#splitting the sets into qualitative and quantitative for dummy variable coercion
#training data
XtrainQual = Xtrain %>% select(c(term,
grade,
sub_grade,
home_ownership,
verification_status,
pymnt_plan,
purpose,
addr_state,
last_credit_pull_d)) %>% mutate_all(factor) %>% as.data.frame(.)
XtrainQuan = Xtrain %>% select(-c(term,
grade,
sub_grade,
home_ownership,
verification_status,
pymnt_plan,
purpose,
addr_state,
last_credit_pull_d)) %>% as.data.frame(.)
#test data
XtestQual = Xtest %>% select(c(term,
grade,
sub_grade,
home_ownership,
verification_status,
pymnt_plan,
purpose,
addr_state,
last_credit_pull_d)) %>% mutate_all(factor) %>% as.data.frame(.)
XtestQuan = Xtest %>% select(-c(term,
grade,
sub_grade,
home_ownership,
verification_status,
pymnt_plan,
purpose,
addr_state,
last_credit_pull_d)) %>% as.data.frame(.)
str(XtrainQual)
str(XtestQual)
#pymnt_plan only has 1 level the test set so I am going to remove it since I cannot create dummy variables for it.
XtrainQual = XtrainQual %>% select(-pymnt_plan)
XtestQual = XtestQual %>% select(-pymnt_plan)
#I am filtering for zero variance before I do this because I am getting an error that I can only create dummy variables on factors with 2 or more levels.
#just a note for myself. I tried to create a dummy model for each set but it did not work since the sets have factors with different levels.
dummyModel = dummyVars(~., data = XtrainQual, fullRank=TRUE)
XtrainQualDummy = predict(dummyModel, XtrainQual)
Xtrain = cbind(XtrainQualDummy, XtrainQuan)
XtestQualDummy = predict(dummyModel, XtestQual)
Xtest = cbind(XtestQualDummy, XtestQuan)
dim(Xtrain)
dim(Xtest)
#predictors = select(trainingData, -loan_status)
#outcome = select(trainingData, loan_status) %>% unlist(.)
#trainingData = downSample(x=predictors, y=outcome, yname='loan_status')
XandYtrain = cbind(Xtrain, Ytrain)
XandYtrain = rename(XandYtrain, loan_status=Ytrain)
#downsample function
predictors = select(XandYtrain, -loan_status)
outcome = select(XandYtrain, loan_status) %>% unlist(.)
XandYtrain = downSample(x=predictors, y=outcome, yname='loan_status')
XtrainD = select(XandYtrain, -loan_status)
YtrainD = select(XandYtrain, loan_status) %>% unlist(.)
YtrainRelevel = relevel(YtrainD, ref = 'Default') %>% unlist()
YtestRelevel = relevel(Ytest, ref = 'Default') %>% unlist()
#code for the logistic regression model
outLogistic = train(x = XtrainD, y = YtrainRelevel,
method = 'glm', trControl = trainControl(method='cv',number=10))
summary(outLogistic)
YhattestProb = predict(outLogistic, Xtest, type = 'prob')
#Checking how well calibrated the probabilities are
calibProbs = calibration(YtestRelevel ~ YhattestProb$`Default`)
xyplot(calibProbs)
#Getting default confusion matrix
Yhattest = predict(outLogistic, Xtest, type = 'raw')
confusionMatrixOutLog = confusionMatrix(reference = YtestRelevel, data = Yhattest)
print(confusionMatrixOutLog$table)
print(confusionMatrixOutLog$overall[1:2])
print(confusionMatrixOutLog$byClass[1:2])
#ROC curve
rocCurveLog = roc(Ytest, YhattestProb$`Default`)
plot(rocCurveLog, legacy.axes=TRUE)
rocCurveLog$auc
thresholds = rocCurveLog$thresholds
sort(thresholds)[1:3]
sort(thresholds, decreasing = TRUE)[1:3]
XtrainMat = as.matrix(XtrainD)
XtestMat = as.matrix(Xtest)
K=10
trainControl = trainControl(method = "repeatedcv", repeats=2, number = K)
set.seed(123)
ridgeOut = cv.glmnet(XtrainMat ,YtrainRelevel, alpha=0, family='binomial', nfolds=10, ncv=2, standardize = FALSE)
minLambda = min(ridgeOut$lambda)
lambdaNew = seq(minLambda, minLambda*0.01,length=25)
ridgeOut = cv.glmnet(x = XtrainMat, y = YtrainRelevel, alpha = 0, family='binomial', nfolds=10,
standardize=FALSE, lambda = lambdaNew)
Probridge = predict(ridgeOut, XtestMat, s = ridgeOut$lambda.min, type='response')
Yhattestridge = ifelse(Probridge > 0.5, 'Fully Paid', 'Default')
#Getting default confusion matrix
#Confusion Matrix
confusionMatrixR = table(Yhattestridge, Ytest)
confusionMatrixR
#ROC curve
rocOutR = roc(response=Ytest, Probridge)
plot(rocOutR)
rocOutR$auc
set.seed(123)
lassoOut = cv.glmnet(XtrainMat ,YtrainRelevel, alpha=1, family='binomial', nfolds=10, ncv=2, standardize = FALSE)
minLambda = min(lassoOut$lambda)
lambdaNew = seq(minLambda, minLambda*0.01,length=25)
lassoOut = cv.glmnet(x = XtrainMat, y = YtrainRelevel, alpha = 1, family='binomial', nfolds=10,
standardize=FALSE, lambda = lambdaNew)
Problasso = predict(lassoOut, XtestMat, s = lassoOut$lambda.min, type='response')
Yhattestlasso = ifelse(Problasso > 0.5, 'Fully Paid', 'Default')
#Confusion Matrix
confusionMatrixL = table(Yhattestlasso, Ytest)
confusionMatrixL
#ROC curve
rocOutL = roc(response=Ytest, Problasso)
plot(rocOutL)
rocOutL$auc
set.seed(2)
#Need to increase the range that we allow lamda take on.
tuneGrid = expand.grid('alpha'=c(0,.25,.5,.75, 1),
'lambda' = seq(0.0001, .01, length.out = 100))
elasticOut = train(x = XtrainMat, y = YtrainRelevel,
method = "glmnet",
trControl = trainControl,
tuneGrid = tuneGrid)
#Getting the fitted model using the CV minimizing solution
glmnetOut = glmnet(x = XtrainMat, y = YtrainRelevel,
alpha = elasticOut$bestTune$alpha, family = 'binomial',
standardize = FALSE)
probHattestGlmnet = predict(glmnetOut, XtestMat, s=elasticOut$bestTune$lambda,
type = 'response')
YhattestGlmnet = ifelse(probHattestGlmnet > 0.5, 'Fully Paid', 'Default')
#Active set
betaHat = coef(glmnetOut, s=elasticOut$bestTune$lambda)
betaHat = (betaHat[-1,])
important = abs(betaHat) > 0.01
sort((betaHat[important]))
table(x$pur)
#Confusion Matrix
confusionMatrixEL = table(YhattestGlmnet, Ytest)
confusionMatrixEL
#ROC curve
rocOutEL = roc(response=Ytest, probHattestGlmnet)
plot(rocOutEL)
rocOutEL$auc
#adjusting data types
#Xtrain
Xtrainfull = cbind(YtrainRelevel,XtrainMat) %>% as.data.frame()
XtrainfullMat = select(Xtrainfull, -YtrainRelevel) %>% as.matrix()
dimnames(XtrainfullMat) = NULL
#Ytrain
Ytrainfull = select(Xtrainfull, YtrainRelevel) %>% unlist() %>% as.vector()
Ytrainfull = to_categorical(Ytrainfull)
#Xtest
Xtestfull = cbind(YtestRelevel,XtestMat) %>% as.data.frame()
XtestfullMat = select(Xtestfull, -YtestRelevel) %>% as.matrix()
dimnames(XtestfullMat) = NULL
#Ytest
Ytestfull = select(Xtestfull, YtestRelevel) %>% unlist() %>% as.vector()
Ytestfull = to_categorical(Ytestfull)
set.seed(123)
model = keras_model_sequential() %>%
layer_dense(units = 256, activation = "relu",
input_shape = dim(XtrainfullMat)[[2]]) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 128, activation = "relu",
input_shape = dim(XtrainfullMat)[[2]]) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 64, activation = "relu",
input_shape = dim(XtrainfullMat)[[2]]) %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = 8, activation = "relu",
input_shape = dim(XtrainfullMat)[[2]]) %>%
layer_dense(units = 4, activation = "relu",
input_shape = dim(XtrainfullMat)[[2]]) %>%
layer_dense(units = 2, activation = "relu",
input_shape = dim(XtrainfullMat)[[2]]) %>%
layer_dense(units = 3, activation="sigmoid")
model
model = model %>% compile(optimizer = "rmsprop",
loss = "binary_crossentropy",
metrics = "BinaryAccuracy")
callbacks_list = list(callback_early_stopping(monitor = "val_loss", patience = 15))
my_model = model %>% fit(XtrainfullMat, Ytrainfull, epoch=50, batch_size=25, validation_data=list(XtestfullMat, Ytestfull))
model %>% evaluate(XtestfullMat, Ytestfull)
#confusion Matrix
prob = model %>% predict(XtestfullMat) %>% k_argmax() %>% as.numeric()
Ytestfull = Ytestfull %>% k_argmax() %>% as.numeric()
prob = as.factor(prob) %>% recode("1" = "Default", "2" = "paid")
Ytestfull2 = as.factor(Ytestfull) %>% recode("1" = "Default","2" = "paid")
confusionMatrixOutNN = confusionMatrix(reference = Ytestfull2, data = prob)
confusionMatrixOutNN$table
print(confusionMatrixOutNN$overall[1:2])
print(confusionMatrixOutNN$byClass[1:2])
set.seed(123)
#It says that 'Fully Paid' needs to be a test r name for it to work so I rename it to 'Paid' here
YtrainFDA = as.character(YtrainRelevel)
YtrainFDA = sub("Fully ", "", YtrainFDA) %>% as.factor() %>% unlist()
YtestFDA = as.character(YtestRelevel)
YtestFDA = sub("Fully ", "", YtestFDA) %>% as.factor() %>% unlist()
require(doParallel)
cl = makeCluster(5)
registerDoParallel(cl)
fdaOut = train(x=XtrainMat, y=YtrainFDA,
method = 'fda',
metric = 'Accuracy',
tuneGrid = expand.grid(degree = 1:3, nprune=c(20,25,30)),
trControl = trainControl(method = "cv", number = 3, classProbs=TRUE))
stopCluster(cl)
registerDoSEQ()
plot(fdaOut)
fdaOut$bestTune
#ROC curve
YhattestFDA = predict(fdaOut, XtestMat, type='prob')
rocCurveFDA = roc(YtestFDA, YhattestFDA$`Default`)
plot(rocCurveFDA, legacy.axes=TRUE)
rocCurveFDA$auc
#Confusion Matrix
YhattestFDA = predict(fdaOut, XtestMat)
confusionMatrixOutFDA = confusionMatrix(reference = YtestFDA, data = YhattestFDA)
confusionMatrixOutFDA$table
print(confusionMatrixOutFDA$overall[1:2])
print(confusionMatrixOutFDA$byClass[1:2])
set.seed(123)
Ytrainsvm = as.character(YtrainRelevel)
Ytrainsvm = sub("Fully ", "", Ytrainsvm) %>% as.factor() %>% unlist()
Ytestsvm = as.character(YtestRelevel)
Ytestsvm = sub("Fully ", "", Ytestsvm) %>% as.factor() %>% unlist()
svmOut = train(x=XtrainMat, y=Ytrainsvm,
method='svmLinear',
trControl=trainControl(method = "cv", number = 3, classProbs=TRUE),
tuneGrid=expand.grid(C=seq(0.01,0.15,length.out=10)))
svmOut
plot(svmOut)
#ROC curve
Yhattestsvm = predict(svmOut, XtestMat, type = 'prob')
rocCurvesvm = roc(Ytestsvm, Yhattestsvm$'Default')
plot(rocCurvesvm, legacy.axes=TRUE)
rocCurvesvm$auc
#confusion matrix
Yhattestsvm = predict(svmOut, XtestMat)
confusionMatrixOutsvm = confusionMatrix(reference = Ytestsvm, data = Yhattestsvm)
confusionMatrixOutsvm$table
print(confusionMatrixOutsvm$overall[1:2])
print(confusionMatrixOutsvm$byClass[1:2])
set.seed(123)
Ytrainsvm = as.character(YtrainRelevel)
Ytrainsvm = sub("Fully ", "", Ytrainsvm) %>% as.factor() %>% unlist()
Ytestsvm = as.character(YtestRelevel)
Ytestsvm = sub("Fully ", "", Ytestsvm) %>% as.factor() %>% unlist()
knnOut   = train(x = XtrainMat, y = Ytrainsvm,
method = "knn",
tuneGrid = expand.grid(k=c(100,105,110,115,120)),
trControl = trainControl(method='cv',number=3,classProbs=TRUE))
knnOut$bestTune
#ROC curve
probKNN = predict(knnOut, XtestMat, type='prob')
rocCurveKNN = roc(Ytestsvm, probKNN$'Default')
plot(rocCurveKNN, legacy.axes=TRUE)
rocCurveKNN$auc
#confusion matrix
probKNN = predict(knnOut, XtestMat)
confusionMatrixOutKNN = confusionMatrix(reference = Ytestsvm, data = probKNN)
confusionMatrixOutKNN$table
print(confusionMatrixOutKNN$overall[1:2])
print(confusionMatrixOutKNN$byClass[1:2])
K=10
trainControl = trainControl(method = "repeatedcv", repeats=2, number = K, classProbs=TRUE)
#It says that 'Fully Paid' needs to be a valid r name for it to work so I rename it to 'Paid' here
YtrainT = as.character(YtrainRelevel)
YtrainT = sub("Fully ", "", YtrainT) %>% as.factor() %>% unlist()
YtestT = as.character(YtestRelevel)
YtestT = sub("Fully ", "", YtestT) %>% as.factor() %>% unlist()
set.seed(123)
tuneGrid = data.frame(cp=c(0,0.001,0.005,0.008,0.01,0.013,0.015,0.02))
rpartOut = train(x = XtrainMat, y = YtrainT,
method = "rpart",
tuneGrid = tuneGrid,
metric='Kappa',
trControl = trainControl)
rpartOut$bestTune
plot(rpartOut)
plot(rpartOut$finalModel,margin= rep(.1,4))
text(rpartOut$finalModel, cex = 0.7, digits = 1)
#ROC curve
YhattestTree = predict(rpartOut, XtestMat, type='prob')
rocCurveTree = roc(YtestT, YhattestTree$'Default')
plot(rocCurveTree, legacy.axes=TRUE)
rocCurveTree$auc
#confusion matrix
YhattestTree = predict(rpartOut, XtestMat)
confusionMatrixOutT = confusionMatrix(reference = YtestT, data = YhattestTree)
confusionMatrixOutT$table
print(confusionMatrixOutT$overall[1:2])
print(confusionMatrixOutT$byClass[1:2])
set.seed(123)
tuneGridRanger = data.frame(splitrule = 'gini',min.node.size = c(15,20,25,35),
mtry = round(sqrt(ncol(XtrainMat))))
rfOut = train(x = XtrainMat, y = YtrainT,
method = "ranger",
num.trees = 150,
tuneGrid = tuneGridRanger,
metric = 'Accuracy',
trControl = trainControl(method = "cv", number = 5,classProbs=TRUE),
importance = 'permutation')
varImp(rfOut)
plot(rfOut)
rfOut$bestTune
rfOut$variable.importance
rfOut = train(x = XtrainMat, y = YtrainT,
method = "ranger",
num.trees = 200,
tuneGrid = rfOut$bestTune,
metric = 'Accuracy',
trControl = trainControl(method = 'none', classProbs=TRUE))
#ROC curve
YhattestRF = predict(rfOut, XtestMat, type='prob')
rocCurveRF = roc(YtestT, YhattestRF$`Default`)
plot(rocCurveRF, legacy.axes=TRUE)
rocCurveRF$auc
#confusion matrix
YhattestRF = predict(rfOut, XtestMat)
confusionMatrixOutRF = confusionMatrix(reference = YtestT, data = YhattestRF)
confusionMatrixOutRF$table
print(confusionMatrixOutRF$overall[1:2])
print(confusionMatrixOutRF$byClass[1:2])
set.seed(123)
tuneGrid = data.frame('nrounds'=c(1000,1250,1500,1750),
'max_depth' = c(2,3,4,5),
'eta' = c(0.01,0.02,0.03,0.04),
'gamma' = c(0,0.1,0.15,0.25),
'colsample_bytree' = c(0.05,0.10,0.15,0.25),
'min_child_weight' = c(0,0.25,0.5,1),
'subsample' = c(1,0.9,0.8,0.7))
length(YtrainT)
boostOut = train(x = XtrainMat, y = YtrainT,
method = "xgbTree",
tuneGrid = tuneGrid,
metric = 'Accuracy',
trControl = trainControl(method = "cv", number = 5,classProbs=TRUE))
boostOut$results
boostOut$bestTune
#ROC curve
Yhattestboost = predict(boostOut, XtestMat, type='prob')
rocCurveboost = roc(YtestT, Yhattestboost$`Default`)
plot(rocCurveboost, legacy.axes=TRUE)
rocCurveboost$auc
#confusion matrix
Yhattestboost = predict(boostOut, XtestMat)
confusionMatrixOutboost = confusionMatrix(reference = YtestT, data = Yhattestboost)
confusionMatrixOutboost$table
print(confusionMatrixOutboost$overall[1:2])
print(confusionMatrixOutboost$byClass[1:2])
print(confusionMatrixOutLog$table)
rocCurveLog$auc
confusionMatrixR
rocOutR$auc
confusionMatrixL
rocOutL$auc
confusionMatrixEL
rocOutEL$auc
table(prob, Ytestfull)
confusionMatrixOutFDA$table
print(confusionMatrixOutFDA$overall[1:2])
print(confusionMatrixOutFDA$byClass[1:2])
rocCurveFDA$auc
confusionMatrixOutsvm$table
print(confusionMatrixOutsvm$overall[1:2])
print(confusionMatrixOutsvm$byClass[1:2])
rocCurvesvm$auc
confusionMatrixOutKNN$table
print(confusionMatrixOutKNN$overall[1:2])
print(confusionMatrixOutKNN$byClass[1:2])
rocCurveKNN$auc
confusionMatrixOutT$table
print(confusionMatrixOutT$overall[1:2])
print(confusionMatrixOutT$byClass[1:2])
rocCurveTree$auc
confusionMatrixOutRF$table
print(confusionMatrixOutRF$overall[1:2])
print(confusionMatrixOutRF$byClass[1:2])
rocCurveRF$auc
confusionMatrixOutboost$table
print(confusionMatrixOutboost$overall[1:2])
print(confusionMatrixOutboost$byClass[1:2])
rocCurveboost$auc
sensitivity(confusionMatrixOutLog$table)
print(confusionMatrixOutLog$table)
rocCurveLog$auc
sensitivity(confusionMatrixOutLog$table)
specificity(confusionMatrixOutLog$table)
confusionMatrixR
sensitivity(confusionMatrixOutLog$table)
specificity(confusionMatrixOutLog$table)
rocOutR$auc
print(confusionMatrixOutLog$table)
sensitivity(confusionMatrixOutLog$table)
specificity(confusionMatrixOutLog$table)
rocCurveLog$auc
confusionMatrixL
sensitivity(confusionMatrixOutL$table)
confusionMatrixL
sensitivity(confusionMatrixL$table)
confusionMatrixL$table
confusionMatrixL
confusionMatrixL
sensitivity(confusionMatrixL)
specificity(confusionMatrixL)
rocOutL$auc
confusionMatrixEL
sensitivity(confusionMatrixOutEL)
confusionMatrixEL
confusionMatrixEL
sensitivity(confusionMatrixEL)
specificity(confusionMatrixEL)
rocOutEL$auc
table(prob, Ytestfull)
sensitivity(table(prob, Ytestfull))
confusionMatrixOutNN$table
print(confusionMatrixOutNN$overall[1:2])
print(confusionMatrixOutNN$byClass[1:2])
accuracy(confusionMatrixOutLog$table)
print(confusionMatrixOutLog$table)
print("accuracy")
sum(diag(confusionMatrixOutLog$table))/sum(confusionMatrixOutLog$table)
print("sensitivity")
sensitivity(confusionMatrixOutLog$table)
print("specificity")
specificity(confusionMatrixOutLog$table)
rocCurveLog$auc
confusionMatrixR
sum(diag(confusionMatrixR$table))/sum(confusionMatrixR$table)
confusionMatrixR
sum(diag(confusionMatrixR))/sum(confusionMatrixR)
sensitivity(confusionMatrixOutLog$table)
specificity(confusionMatrixOutLog$table)
rocOutR$auc
print(confusionMatrixOutLog$table)
sum(diag(confusionMatrixOutLog$table))/sum(confusionMatrixOutLog$table)
sensitivity(confusionMatrixOutLog$table)
specificity(confusionMatrixOutLog$table)
rocCurveLog$auc
confusionMatrixL
sum(diag(confusionMatrixL))/sum(confusionMatrixL)
sensitivity(confusionMatrixL)
specificity(confusionMatrixL)
rocOutL$auc
confusionMatrixEL
sum(diag(confusionMatrixEL))/sum(confusionMatrixEL)
sensitivity(confusionMatrixEL)
specificity(confusionMatrixEL)
rocOutEL$auc
max(xQuan$revol_bal)
max(x$revol_bal)
