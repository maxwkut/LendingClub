XQualtrain = trainingData %>% select(c(term,
grade,
sub_grade,
home_ownership,
verification_status,
issue_d,
pymnt_plan,
purpose,
addr_state,
last_credit_pull_d))
XQuantrain = trainingData %>% select(-c(term,
grade,
sub_grade,
home_ownership,
verification_status,
issue_d,
loan_status,
pymnt_plan,
purpose,
addr_state,
last_credit_pull_d))
Ytrain     = trainingData %>% select(loan_status) %>% unlist()
#You can see how downsampling balances out the class imbalance
table(Y)
table(Ytrain)
#combine qual. and quan. features
Xtest      = select(cbind(dataQual[-trainIndex,],dataQuan[-trainIndex,]), -loan_status)
Ytest      = Y[-trainIndex,]
modeImpute = function(Xqual){
tbl = table(Xqual)
Xqual[is.na(Xqual)] = names(tbl)[which.max(tbl)]
return(Xqual)
}
XQuantrain = XQuantrain %>%
preProcess(method = 'medianImpute')%>%
predict(newdata = XQuantrain)
XQualtrain = XQualtrain %>% mutate(across(.cols=everything(), modeImpute))
#Check missing one more time to be sure the code worked (No more missing values!)
sapply(XQuantrain, function(x) sum(is.na(x)))
#Here are the structures if you guys are interested
str(XQualtrain)
str(XQuantrain)
str(Ytrain)
str(Xtest)
str(Ytest)
datacorr = cor(XQuantrain)
corrplot(datacorr, order= 'hclust', t1.cex= .35)
str(XQuantrain)
dim(XQuantrain)
highCorr = findCorrelation(datacorr, .85, verbose=T, names=T)
XQuantrain= select(all_of(XQuantrain), -any_of((highCorr)))
str(XQuantrain)
dim(XQuantrain)
Xtrain = cbind(XQualtrain, XQuantrain) # combine qualitative and quantitative features
dim(Xtrain) # total number of observations and features in the training set
names(Xtrain) # names of remaining features
XQualtest = select_if(Xtest, is.factor)
dummyModel = dummyVars(~., data = XQualtrain, fullRank=TRUE)
XQualtrainDummy = predict(dummyModel, XQualtrain)
XtrainFull = cbind(XQualtrainDummy, XQuantrain)
XQualtestDummy = predict(dummyModel, XQualtest)
XQuantest = select_if(Xtest, is.numeric)
XtestFull = cbind(XQualtestDummy, XQuantest)
str(Ytrain)
#code for the logistic regression model
YtrainRelevel = relevel(Ytrain, ref = 'Default')
YtestRelevel = relevel(Ytest, ref = 'Default')
trControl = trainControl(method = 'none')
outLogistic = train(x = XtrainFull, y = YtrainRelevel,
method = 'glm', trControl = trControl)
summary(outLogistic)
YhatTestProb = predict(outLogistic, XtestFull, type = 'prob')
#Here are the probabilities
head(YhatTestProb)
#Checking how well calibrated the probabilities are
calibProbs = calibration(YtestRelevel ~ YhatTestProb$`Default`)
xyplot(calibProbs)
#Getting default confusion matrix
YhatTest = predict(outLogistic, XtestFull, type = 'raw')
confusionMatrixOut = confusionMatrix(reference = YtestRelevel, data = YhatTest)
print(confusionMatrixOut$table)
print(confusionMatrixOut$overall[1:2])
print(confusionMatrixOut$byClass[1:2])
#Getting default confusion matrix
YhatTest = predict(outLogistic, XtestFull, type = 'raw')
confusionMatrixOut = confusionMatrix(reference = YtestRelevel, data = YhatTest)
print(confusionMatrixOut$table)
print(confusionMatrixOut$overall[1:2])
print(confusionMatrixOut$byClass)
#Getting default confusion matrix
YhatTest = predict(outLogistic, XtestFull, type = 'raw')
confusionMatrixOut = confusionMatrix(reference = YtestRelevel, data = YhatTest)
print(confusionMatrixOut$table)
print(confusionMatrixOut$overall)
print(confusionMatrixOut$byClass)
#Getting default confusion matrix
YhatTest = predict(outLogistic, XtestFull, type = 'raw')
confusionMatrixOut = confusionMatrix(reference = YtestRelevel, data = YhatTest)
print(confusionMatrixOut$table)
print(confusionMatrixOut$overall[1:2])
print(confusionMatrixOut$byClass[1:2])
#ROC curve
rocCurve = roc(Ytest, YhatTestProb$`Default`)
rocCurve = roc(Ytest, YhatTestProb$`Default`)
knitr::opts_chunk$set(echo = TRUE)
packs = c('dplyr','ggplot2','caret','corrplot','e1071','readr', 'reshape2', 'pROC')
lapply(packs,require,character.only=T)
#ROC curve
rocCurve = roc(Ytest, YhatTestProb$`Default`)
plot(rocCurve, legacy.axes=TRUE)
rocCurve$auc
thresholds = rocCurve$thresholds
sort(thresholds)[1:3]
sort(thresholds, decreasing = TRUE)[1:3]
#Getting confusion matrix for particular sensitivity
pt5 = which.min(rocCurve$sensitivities >= 0.8)
threshold = thresholds[pt5]
specificity = rocCurve$specificities[pt5]
sensitivity = rocCurve$sensitivities[pt5]
YhatTestThresh = ifelse(YhatTestProb$`Default` > threshold,
'Default', 'Fully Paid') %>% as.factor()
confusionMatrixOut = confusionMatrix(reference = YtestRelevel, data = YhatTestThresh)
confusionMatrixOut$table
print(confusionMatrixOut$overall[1:2])
print(confusionMatrixOut$byClass[1:2])
set.seed(2)
XtrainMat = as.matrix(XtrainFull)
XtestMat = as.matrix(XtestFull)
#fitting the logistic elastic net
K = 3
trainControl = trainControl(method = "cv", number = K)
tuneGrid = expand.grid('alpha'=c(0,.25,.5,.75, 1),
'lambda' = seq(0.0001, .001, length.out = 30))
elasticOut = train(x = XtrainMat, y = Ytrain,
method = "glmnet",
trControl = trainControl,
tuneGrid = tuneGrid)
elasticOut$bestTune
#Getting the fitted model using the CV minimizing solution
glmnetOut = glmnet(x = XtrainMat, y = relevel(Ytrain, ref = 'Default'),
alpha = elasticOut$bestTune$alpha, family = 'binomial',
standardize = FALSE)
knitr::opts_chunk$set(echo = TRUE)
packs = c('dplyr','ggplot2','caret','corrplot','e1071','readr', 'reshape2', 'pROC', 'glmnet')
lapply(packs,require,character.only=T)
#Getting the fitted model using the CV minimizing solution
glmnetOut = glmnet(x = XtrainMat, y = relevel(Ytrain, ref = 'Default'),
alpha = elasticOut$bestTune$alpha, family = 'binomial',
standardize = FALSE)
probHatTestGlmnet = predict(glmnetOut, XtestMat, s=elasticOut$bestTune$lambda,
type = 'response')
dim(XtrainMat)
dim(XtestMat)
dim(XtrainFull)
dim(XtestFull)
dim(XQuantrain)
dim(XQuantest)
dim(XQuantrain)
dim(XQuantest)
str(XQualtrain)
str(XQuantrain)
str(Ytrain)
str(Xtest)
str(Ytest)
knitr::opts_chunk$set(echo = TRUE)
packs = c('dplyr','ggplot2','caret','corrplot','e1071','readr', 'reshape2', 'pROC', 'glmnet')
lapply(packs,require,character.only=T)
data = read_csv("Data/LoanStats3a.csv")
#Transform loan status
data$loan_status[data$loan_status == "Charged Off"] = "Default"
data$loan_status[data$loan_status == "Does not meet the credit policy. Status:Charged Off"] = "Default"
data= data %>% filter(loan_status == "Default" | loan_status == "Fully Paid")
unique(data$loan_status)
data%>%select(loan_status)%>%group_by(loan_status)%>%count(.)
anyNA(data) # to see if there are any missing values in the dataset
dim(data) # number of observations and features
ggplot_missing <- function(x){
if(!require(reshape2)){warning('you need to install reshape2')}
require(reshape2)
require(ggplot2)
#### This function produces a plot of the missing data pattern
#### in x. It is a modified version of a function in the 'neato' package
x %>%
is.na %>%
melt %>%
ggplot(data = .,
aes(x = Var2,
y = Var1)) +
geom_raster(aes(fill = value)) +
scale_fill_grey(name = "",
labels = c("Present","Missing")) +
theme_minimal() +
theme(axis.text.x = element_text(angle=45, vjust=0.5)) +
labs(x = "Variables in Dataset",
y = "Rows / observations")
}
round(colMeans(is.na(data))*100,3)
data = data %>% select_if(~mean(is.na(.))<=0.33) # drop features with a lot of NAs
dim(data) # dimensions of altered dataset
table(sapply(data[1,],class)) # number of features per data type
str(data) # overview of data types
sapply(data,function(x){ length(unique(x))})
# features with only one value that will be dropped:
#     collections_12_mths_ex_med,
#     application_type,
#     policy_code,
#     chargeoff_within_12_mths
#     init_list_status
#     acc_now_delinq
#     delinq_amnt
data = data %>% select(-c(collections_12_mths_ex_med,
application_type,
policy_code,
chargeoff_within_12_mths,
initial_list_status,
acc_now_delinq,
delinq_amnt,
tax_liens))
# These features are uninformative and will be dropped:
# We may need to state why they are uninformative.
# zip_code
# id
# member_id
# emp_title
# title
# url
# desc
data = data %>% select(-c(zip_code,
id,
member_id,
emp_title,
title,
url,
desc))
# Keep only the features that are available to us before someone invested on the loan.
# Features that were not available before loan disbursement:
# total_pymnt
# total_pymnt_inv
# total_rec_prncp,
# total_rec_int,
# total_rec_late_fee,
# recoveries,
# collection_recovery_fee,
# last_pymnt_d,
# last_pymnt_amnt,
data = data %>% select(-c(total_pymnt,
total_pymnt_inv,
total_rec_prncp,
total_rec_int,
total_rec_late_fee,
recoveries,
collection_recovery_fee,
last_pymnt_d,
last_pymnt_amnt))
##### Dates converted to factors for now
# Are you guys cool with converting some of these dates to numeric values where we can? # I think they could be a little more useful this way instead of just leaving them out of the model or converting them all as factors.
#issue_d: date
#last_credit_pull_d: date
#earliest_cr_line: date
# Converting employment length to number of years they have been employed.
data$emp_length[which(data$emp_length == "10+ years")] = 10
data$emp_length[which(data$emp_length == "< 1 year")] = 0
data$emp_length[which(data$emp_length == "n/a")] = NA
data$emp_length = sub(" years", "", data$emp_length)
data$emp_length = sub(" year", "", data$emp_length)
data$emp_length = as.numeric(data$emp_length)
#Converted issue_d to the month that the loan was issued
data$issue_d = sub("-.*", "", data$issue_d)
#This code will convert earliest_cr_line to the number of years since their earliest credit line. Also, I think this was last updated in 2008 since the earliest credit line for someone was in 2008.
data$earliest_cr_line = sub("-[[:alpha:]]+","", data$earliest_cr_line)
data$earliest_cr_line = sub(".*-", "", data$earliest_cr_line) %>% as.numeric(.)
current = 8 - data$earliest_cr_line[data$earliest_cr_line <= 8]
old = na.omit(data$earliest_cr_line[data$earliest_cr_line > 8]) %>% as.character(.)
old = paste("19",old)
old = sub(" ","", old) %>% as.numeric(.)
old = 2008 - old
current = as.character(current)
old = as.character(old)
data$earliest_cr_line = as.numeric(c(current, old))
#This converts last_credit_pull_d to the month of their last credit pull.
data$last_credit_pull_d = sub("-.*", "", data$last_credit_pull_d)
#Gets rid of the percent signs for revol_util and int_rate and converts them to numeric
data$revol_util = as.numeric(sub("%","",data$revol_util))
data$int_rate = as.numeric(sub("%","",data$int_rate))
#convert data types
dataQual = data %>% select(c(term,
grade,
sub_grade,
home_ownership,
verification_status,
issue_d,
loan_status,
pymnt_plan,
purpose,
addr_state,
last_credit_pull_d)) %>% mutate_all(factor)
dataQuan = data %>% select(-c(term,
grade,
sub_grade,
home_ownership,
verification_status,
issue_d,
loan_status,
pymnt_plan,
purpose,
addr_state,
last_credit_pull_d))
#final result
table(sapply(cbind(dataQual[1,],dataQuan[1,]),class)) # number of features per data type
str(dataQual)
str(dataQuan)
#Removing features that do not have at least some nontrivial variation
sdVec = apply(dataQuan, 2, sd, na.rm=TRUE)
which(sdVec < 0.0001)
#Everything has at least some nontrivial variation
#Checking features for imbalanced frequencies. Pg 45 in the book recommends removing features if the fraction of unique values to sample size is low (10%) and the ratio of the most prevalent value to 2nd most prevalent value is large (around 20). if both criteria holds they say it may be advantageous to remove it. On pg 55 they show the code for this.
nearZeroVar(dataQuan, saveMetrics = TRUE)
table(dataQuan$out_prncp)
table(dataQuan$out_prncp_inv)
table(dataQuan$pub_rec_bankruptcies)
#these are all good candidates to remove based on this metric so I am going to remove them.
dataQuan = dataQuan %>% select(-c(out_prncp,
out_prncp_inv,
pub_rec_bankruptcies))
#Centering and scaling the numeric features
dataQuan = dataQuan %>% preProcess(.) %>% predict(newdata = dataQuan)
str(dataQuan)
(skewed= apply(dataQuan, 2, skewness, na.rm=TRUE))
skewFeats = names(which(abs(skewed) > 1.5))
dataQuanYJ = dataQuan %>%
select(abs(contains(skewFeats))) %>%
preProcess(method = 'YeoJohnson', na.rm=TRUE) %>%
predict(dataQuan %>% select(contains(skewFeats)))
dataQuanNotSkew = dataQuan %>% select(!contains(skewFeats))
apply(dataQuanYJ, 2, skewness, na.rm=TRUE)
dataQuanYJ = cbind(dataQuanYJ, dataQuanNotSkew)
pcaOut = prcomp(na.omit(dataQuanYJ,scale=TRUE,center=TRUE))
XQuanScores = data.frame(pcaOut$x)
ggplot(data = XQuanScores) + geom_point(aes(x = PC1, y = PC2)) +
coord_cartesian(xlim=range(XQuanScores$PC1), ylim=range(XQuanScores$PC2))
#Counting the missing data
sapply(dataQuan, function(x) sum(is.na(x)))
set.seed(123)
Y = select(dataQual,loan_status) %>% unlist()
# NOTE: Might want to consider stratified train test split because of unequal proportions in the supervisor
trainIndex = createDataPartition(Y, p=.75, list= FALSE) %>% as.vector()
Y = as.data.frame(Y)
#code for downsampling
XFullTrain = cbind(dataQual, dataQuan)
XFullTrain = XFullTrain[trainIndex, ]
predictors = select(XFullTrain, -loan_status)
outcome = select(XFullTrain, loan_status) %>% unlist(.)
trainingData = downSample(x=predictors, y=outcome, yname='loan_status')
# split train features into qual and quan for imputation
XQualtrain = trainingData %>% select(c(term,
grade,
sub_grade,
home_ownership,
verification_status,
issue_d,
pymnt_plan,
purpose,
addr_state,
last_credit_pull_d))
XQuantrain = trainingData %>% select(-c(term,
grade,
sub_grade,
home_ownership,
verification_status,
issue_d,
loan_status,
pymnt_plan,
purpose,
addr_state,
last_credit_pull_d))
Ytrain     = trainingData %>% select(loan_status) %>% unlist()
#You can see how downsampling balances out the class imbalance
table(Y)
table(Ytrain)
#combine qual. and quan. features
Xtest      = select(cbind(dataQual[-trainIndex,],dataQuan[-trainIndex,]), -loan_status)
Ytest      = Y[-trainIndex,]
modeImpute = function(Xqual){
tbl = table(Xqual)
Xqual[is.na(Xqual)] = names(tbl)[which.max(tbl)]
return(Xqual)
}
XQuantrain = XQuantrain %>%
preProcess(method = 'medianImpute')%>%
predict(newdata = XQuantrain)
XQualtrain = XQualtrain %>% mutate(across(.cols=everything(), modeImpute))
#Check missing one more time to be sure the code worked (No more missing values!)
sapply(XQuantrain, function(x) sum(is.na(x)))
#Here are the structures if you guys are interested
str(XQualtrain)
str(XQuantrain)
str(Ytrain)
str(Xtest)
str(Ytest)
datacorr = cor(XQuantrain)
corrplot(datacorr, order= 'hclust', t1.cex= .35)
str(XQuantrain)
dim(XQuantrain)
highCorr = findCorrelation(datacorr, .85, verbose=T, names=T)
XQuantrain= select(all_of(XQuantrain), -any_of((highCorr)))
XQuantest= select(all_of(XQuantest), -any_of((highCorr)))
highCorr = findCorrelation(datacorr, .85, verbose=T, names=T)
XQuantrain= select(all_of(XQuantrain), -any_of((highCorr)))
Xtest= select(all_of(Xtest), -any_of((highCorr)))
str(XQuantrain)
dim(XQuantrain)
str(Xtest)
Xtrain = cbind(XQualtrain, XQuantrain) # combine qualitative and quantitative features
dim(Xtrain) # total number of observations and features in the training set
names(Xtrain) # names of remaining features
XQualtest = select_if(Xtest, is.factor)
dummyModel = dummyVars(~., data = XQualtrain, fullRank=TRUE)
XQualtrainDummy = predict(dummyModel, XQualtrain)
XtrainFull = cbind(XQualtrainDummy, XQuantrain)
XQualtestDummy = predict(dummyModel, XQualtest)
XQuantest = select_if(Xtest, is.numeric)
XtestFull = cbind(XQualtestDummy, XQuantest)
str(Ytrain)
#code for the logistic regression model
YtrainRelevel = relevel(Ytrain, ref = 'Default')
YtestRelevel = relevel(Ytest, ref = 'Default')
trControl = trainControl(method = 'none')
outLogistic = train(x = XtrainFull, y = YtrainRelevel,
method = 'glm', trControl = trControl)
summary(outLogistic)
YhatTestProb = predict(outLogistic, XtestFull, type = 'prob')
#Here are the probabilities
head(YhatTestProb)
#Checking how well calibrated the probabilities are
calibProbs = calibration(YtestRelevel ~ YhatTestProb$`Default`)
xyplot(calibProbs)
#Getting default confusion matrix
YhatTest = predict(outLogistic, XtestFull, type = 'raw')
confusionMatrixOut = confusionMatrix(reference = YtestRelevel, data = YhatTest)
print(confusionMatrixOut$table)
print(confusionMatrixOut$overall[1:2])
print(confusionMatrixOut$byClass[1:2])
#ROC curve
rocCurve = roc(Ytest, YhatTestProb$`Default`)
plot(rocCurve, legacy.axes=TRUE)
rocCurve$auc
thresholds = rocCurve$thresholds
sort(thresholds)[1:3]
sort(thresholds, decreasing = TRUE)[1:3]
#Getting confusion matrix for particular sensitivity
pt5 = which.min(rocCurve$sensitivities >= 0.8)
threshold = thresholds[pt5]
specificity = rocCurve$specificities[pt5]
sensitivity = rocCurve$sensitivities[pt5]
YhatTestThresh = ifelse(YhatTestProb$`Default` > threshold,
'Default', 'Fully Paid') %>% as.factor()
confusionMatrixOut = confusionMatrix(reference = YtestRelevel, data = YhatTestThresh)
confusionMatrixOut$table
print(confusionMatrixOut$overall[1:2])
print(confusionMatrixOut$byClass[1:2])
set.seed(2)
XtrainMat = as.matrix(XtrainFull)
XtestMat = as.matrix(XtestFull)
#fitting the logistic elastic net
K = 3
trainControl = trainControl(method = "cv", number = K)
tuneGrid = expand.grid('alpha'=c(0,.25,.5,.75, 1),
'lambda' = seq(0.0001, .001, length.out = 30))
elasticOut = train(x = XtrainMat, y = Ytrain,
method = "glmnet",
trControl = trainControl,
tuneGrid = tuneGrid)
elasticOut$bestTune
#Getting the fitted model using the CV minimizing solution
glmnetOut = glmnet(x = XtrainMat, y = relevel(Ytrain, ref = 'Default'),
alpha = elasticOut$bestTune$alpha, family = 'binomial',
standardize = FALSE)
probHatTestGlmnet = predict(glmnetOut, XtestMat, s=elasticOut$bestTune$lambda,
type = 'response')
YhatTestGlmnet = ifelse(probHatTestGlmnet > 0.5, 'Fully Paid', 'Default')
#Active set
betaHat = coef(glmnetOut, s=elasticOut$bestTune$lambda)
betaHat
Sglmnet = abs(betaHat[-1]) > .005
Sglmnet
#ROC curve
rocOut = roc(response=Ytest, YhatTestGlmnet)
#Confusion Matrix
confusionMatrixOut = confusionMatrix(reference = YtestRelevel, data = YhatTestGlmnet)
#Confusion Matrix
confusionMatrixOut = confusionMatrix(reference = Ytest, data = YhatTestGlmnet)
#Active set
betaHat = coef(glmnetOut, s=elasticOut$bestTune$lambda)
betaHat
Sglmnet = abs(betaHat[-1]) > .005
Sglmnet
names(Sglmnet)
names(which(abs(betaHat[-1]) > .005))
which(abs(betaHat[-1]) > .005)
#Active set
betaHat = coef(glmnetOut, s=elasticOut$bestTune$lambda)
betaHat
#Confusion Matrix
confusionMatrixEL = table(YhatTestGlmnet, Ytest)
confusionMatrixEL
#ROC curve
rocOut = roc(response=Ytest, probHatTestGlmnet)
plot(rocOut)
#ROC curve
rocOut = roc(response=Ytest, probHatTestGlmnet)
plot(rocOut)
rocOut$auc
