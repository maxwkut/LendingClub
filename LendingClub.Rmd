---
output: github_document
---
<style type="text/css">

/* Whole document: */
body{
    font-size: 16pt;
  }
/* Headers */
h1{
    font-size: 24pt;
  }
h2{
    font-size: 20pt;
  }
h3{
    font-size: 18pt;
  }
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
packs = c('dplyr','ggplot2','caret','corrplot','e1071','readr', 'reshape2')
lapply(packs,require,character.only=T)
```

```{r data, include=F}
data = read_csv("Data/LoanStats3a.csv")
```


<center>

<font size= "6.5">Predicting Credit Defaults</font>\
\
Bradley Gravitt\
Max Kutschinski\
Shree Karimkolikuzhiyil\
\
`r format(Sys.time(), '%d %B, %Y')`

</center>



# Overview

Insert text here


# Exploratory Analysis

## Missing Values

The goal of this section is to identify features that are eligible for feature wise deletion in order to make the data set easier to navigate. Part II discusses how to handle any remaining missing values. The original dataset contains 42537 observations and 111 variables.

```{r include=F}
anyNA(data) # to see if there are any missing values in the dataset
dim(data) # number of observations and features
```

```{r echo=F, warning=F, message=F, error=F}
ggplot_missing <- function(x){
if(!require(reshape2)){warning('you need to install reshape2')}
require(reshape2)
require(ggplot2)
#### This function produces a plot of the missing data pattern
#### in x. It is a modified version of a function in the 'neato' package
x %>%
  is.na %>%
  melt %>%
  ggplot(data = .,
         aes(x = Var2,
             y = Var1)) +
  geom_raster(aes(fill = value)) +
  scale_fill_grey(name = "",
                  labels = c("Present","Missing")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=45, vjust=0.5)) +
  labs(x = "Variables in Dataset",
       y = "Rows / observations")
}

```

```{r echo=F}
ggplot_missing(data) # visualize missing data
```

The missingness plot indicates that a large amount of features consists of a high percentage of missing values. The following output shows the exact percentages per feature.

```{r echo=F}
round(colMeans(is.na(data))*100,3)
```

Thus, it makes sense to delete features with a large percentage of missing values. The general rule of thumb is to delete any features with 33% or more.

```{r include=F}

data = data %>% select_if(~mean(is.na(.))<=0.33) # drop features with a lot of NAs
dim(data) # dimensions of altered dataset
```
After dropping the features that fall into this category, 53 features remain in the dataset.  Before using any kind of imputation method the data is split into a training and test set. Imputation is only performed on the features of the training set. Mode imputation is used for qualitative features, and median imputation is used for quantitative features.

## Data structures

The following section of code explores the data structures in order to identify any qualitative features that might be coded as quantitative features and vice versa. First, the number of features per data type is displayed.

```{r echo=F}
table(sapply(data[1,],class)) # number of features per data type
```

To get a closer look at the data types for each feature, the following output can be used. 

```{r echo=F}
str(data) # overview of data types
```

Furthermore, the number of unique values per features are displayed.

```{r}
sapply(data,function(x){ length(unique(x))})
```

There are some qualitative features, some coded as character and some as numeric, that need to be converted to factors. In addition, it seems like some features only have one value (besides NA) and should therefore be dropped. After making some transformations, the dataset looks as follows.

```{r echo=F}
# NOTE

##### Dates converted to factors for now

#issue_d: date
#last_pymnt_d: date
#last_credit_pull_d: date
#earliest_cr_line: date

#####

# features with only one value:
#     collections_12_mths_ex_med, 
#     application_type, 
#     policy_code,
#     chargeoff_within_12_mths

# END NOTE

# get rid of percent signs and convert to numeric
data$revol_util = as.numeric(sub("%","",data$revol_util)) 
data$int_rate = as.numeric(sub("%","",data$int_rate))

#convert data types
dataQual = data %>% select(c(term,grade,sub_grade,home_ownership,verification_status,loan_status,pymnt_plan,
                         purpose, initial_list_status, addr_state, zip_code, id, member_id, emp_title,title, issue_d,last_pymnt_d,
                         last_credit_pull_d,earliest_cr_line, emp_length, url, desc)) %>% mutate_all(factor)
dataQuan = data %>% select(-c(names(dataQual),collections_12_mths_ex_med,application_type,policy_code,chargeoff_within_12_mths))

#final result
str(dataQual)
str(dataQuan)
```



```{r IMPUTATION, include=F}
set.seed(123)
Y = select(dataQual,loan_status) %>% unlist() %>% as.vector()
dataQual = select(dataQual,-loan_status)

# NOTE: Might want to consider stratified train test split because of unequal proportions in the supervisor

trainIndex = createDataPartition(Y, p=.75, list= FALSE) %>% as.vector()
Y = as.data.frame(Y)

XQualTrain = dataQual[trainIndex,] # split train features into qual and quan for imputation
XQuanTrain = dataQuan[trainIndex,]
Ytrain     = Y[trainIndex,]
Xtest      = cbind(dataQual[-trainIndex,],dataQuan[-trainIndex,]) #combine qual. and quan. features 
Ytest      = Y[-trainIndex,]

modeImpute = function(Xqual){
  tbl = table(Xqual)
  Xqual[is.na(Xqual)] = names(tbl)[which.max(tbl)]
  return(Xqual)
}

XQuanTrain = XQuanTrain %>% 
  preProcess(method = 'medianImpute')%>%
  predict(newdata = XQuanTrain)

XQualTrain = XQualTrain %>% mutate(across(.cols=everything(), modeImpute))
```


## Removing correlated variables

Quantitative features with high correlation (p>0.85) are problematic and should removed as a result.

```{r, warning = F, error = F, message = F, echo=F}
datacorr = cor(XQuanTrain)
corrplot(datacorr, order= 'hclust', t1.cex= .35)
```

```{r include=F}
highCorr = findCorrelation(datacorr, .85, verbose=T, names=T)
XQuanTrain= select(all_of(XQuanTrain), -any_of((highCorr)))
dim(XQuanTrain)
```

The correlation plot indicates that there are a few features with high correlation in the dataset that should be removed. 

## Extreme observations and skewness

Principal components analysis is used to check for extreme observations. However, it is important to check for skewness first.
Assuming that acceptable values of skewness fall between -1,5 and 1.5, features with values for skewness outside of this range are transformed.

```{r echo=F}
(skewed= apply(XQuanTrain, 2, skewness))
```

The output indicates that some features are heavily skewed.

```{r echo=F}
# NOTE: didn't work

XQuanTrain = XQuanTrain %>%
  select_if(abs(skewed) > 1.5) %>%
  preProcess(method = 'YeoJohnson') %>%
  predict(newdata = XQuanTrain)
```

Extreme observations can be identified via the following PCA output.

```{r echo=F}
pcaOut = prcomp(XQuanTrain,scale=TRUE,center=TRUE)
XQuanTrainScores = data.frame(pcaOut$x)
ggplot(data = XQuanTrainScores) +
geom_point(aes(x = PC1, y = PC2))

```
\
No immediate extreme observations apparent. 


# Methods

## Logistic elastic net

```{r echo=F}
Xtrain = cbind(XQualTrain, XQuanTrain)
# K            = 5
# trainControl = trainControl(method = "cv", number = K)
# tuneGrid     = expand.grid('alpha'=c(.5, 1),'lambda' = seq(0.0001, .01, length.out = 10))
# 
# elasticOut   = train(x= Xtrain, y= Ytrain,
#                      method = "glmnet",
#                      trControl = trainControl, 
#                      tuneGrid = tuneGrid) #### Answer 1.1
# 
# elasticOut$bestTune
# 
# glmnetOut         = glmnet(x = XtrainMat, y = relevel(Ytrain, ref = 'X8'), 
#                            alpha = elasticOut$bestTune$alpha, family = 'binomial')
# probHatTestGlmnet = predict(glmnetOut, XtestMat, s=elasticOut$bestTune$lambda, type = 'response')
# YhatTestGlmnet    = ifelse(probHatTestGlmnet>0.5, 'X1', 'X2')# check with roc curve

```

## SVM

```{r}

```


# Results

# Conclusion
